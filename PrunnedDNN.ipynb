{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist  \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0  \n",
    "x_test = x_test / 255.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
    "l2 = tf.keras.layers.Dense(1000, activation=tf.nn.relu)  \n",
    "l3 = tf.keras.layers.Dense(1000, activation=tf.nn.relu) \n",
    "l4 = tf.keras.layers.Dense(500, activation=tf.nn.relu)\n",
    "l5 = tf.keras.layers.Dense(200, activation=tf.nn.relu)\n",
    "op = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "\n",
    "model = tf.keras.models.Sequential() \n",
    "model.add(l1)  \n",
    "model.add(l2)  \n",
    "model.add(l3)  \n",
    "model.add(l4) \n",
    "model.add(l5)\n",
    "model.add(op) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.2154 - acc: 0.9360\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.1010 - acc: 0.97101s - loss: \n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.0729 - acc: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25e1a9bd3c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',  \n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.fit(x_train, y_train, epochs=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02191258,  0.01259549,  0.03930573, ..., -0.00736624,\n",
       "         -0.04897735, -0.00093672],\n",
       "        [ 0.01131131,  0.01710572, -0.05416338, ...,  0.01650958,\n",
       "          0.03191972,  0.04387422],\n",
       "        [ 0.05234427, -0.04108552, -0.02270708, ...,  0.01225932,\n",
       "         -0.02296691,  0.0392293 ],\n",
       "        ...,\n",
       "        [ 0.02865515, -0.01679286, -0.04772637, ..., -0.01545653,\n",
       "         -0.00290271,  0.04273782],\n",
       "        [ 0.01562636, -0.04175957, -0.05760852, ...,  0.05294022,\n",
       "          0.00492226, -0.03615477],\n",
       "        [-0.02449907, -0.0280659 ,  0.0326672 , ...,  0.00653087,\n",
       "         -0.02022936, -0.04606252]], dtype=float32),\n",
       " array([[ 0.04183542, -0.00999192, -0.00984317, ..., -0.04024448,\n",
       "          0.01396896, -0.01892357],\n",
       "        [ 0.05810023,  0.07590514,  0.05791115, ...,  0.02672741,\n",
       "          0.06498754,  0.05249326],\n",
       "        [-0.10602294, -0.17064266, -0.12187394, ...,  0.04828503,\n",
       "          0.06618211, -0.02595068],\n",
       "        ...,\n",
       "        [-0.01250048,  0.01431054, -0.06346852, ..., -0.09460134,\n",
       "          0.05775027, -0.08146901],\n",
       "        [-0.00761665, -0.046438  , -0.03781056, ...,  0.0350708 ,\n",
       "          0.05525617,  0.00150999],\n",
       "        [ 0.10071379,  0.12266911,  0.10496209, ...,  0.01264748,\n",
       "          0.00036095, -0.03588017]], dtype=float32),\n",
       " array([[-0.06104123,  0.08385545,  0.00629193, ...,  0.03275371,\n",
       "          0.03783432,  0.00214592],\n",
       "        [-0.0507526 , -0.11798286, -0.01431247, ..., -0.00508342,\n",
       "         -0.03094957,  0.00326802],\n",
       "        [-0.07623803,  0.04602599, -0.00819239, ..., -0.08353267,\n",
       "          0.05299097, -0.02143635],\n",
       "        ...,\n",
       "        [-0.03672792, -0.07272623, -0.0133642 , ..., -0.14263414,\n",
       "         -0.08482096,  0.01371534],\n",
       "        [-0.03484878,  0.04435902, -0.01935063, ..., -0.03876846,\n",
       "          0.03232176, -0.07445184],\n",
       "        [ 0.03723584,  0.00764232,  0.02446104, ...,  0.00071736,\n",
       "         -0.00628123,  0.01590047]], dtype=float32),\n",
       " array([[ 0.00953108,  0.05845879, -0.00560346, ...,  0.07328952,\n",
       "         -0.08835714, -0.0627092 ],\n",
       "        [-0.08981235,  0.04923056,  0.00099054, ..., -0.01993279,\n",
       "         -0.13343634,  0.05798058],\n",
       "        [ 0.03534264, -0.09166778,  0.0262662 , ..., -0.01875288,\n",
       "         -0.04016328,  0.00771301],\n",
       "        ...,\n",
       "        [ 0.05711776, -0.04968478, -0.10578924, ...,  0.05523234,\n",
       "          0.00303752, -0.12926973],\n",
       "        [-0.08877045,  0.05503653, -0.09366395, ...,  0.02633612,\n",
       "         -0.00711198,  0.04960173],\n",
       "        [-0.0395353 , -0.04518336,  0.05602723, ..., -0.05647491,\n",
       "         -0.11601841, -0.03582981]], dtype=float32),\n",
       " array([[ 0.03947698, -0.00127149,  0.02028902, ..., -0.16034187,\n",
       "          0.078808  , -0.09174135],\n",
       "        [ 0.13511892, -0.03003007,  0.14179891, ...,  0.04962851,\n",
       "          0.14509423,  0.06306141],\n",
       "        [ 0.12215691, -0.06943797, -0.14873599, ..., -0.15144786,\n",
       "         -0.15782453,  0.01127958],\n",
       "        ...,\n",
       "        [ 0.07751258, -0.03050479,  0.03376438, ...,  0.08658797,\n",
       "         -0.11372186, -0.00218813],\n",
       "        [-0.16048986,  0.02465152, -0.00341952, ..., -0.16427916,\n",
       "          0.02427618, -0.04891379],\n",
       "        [-0.02320906,  0.11870536,  0.06219946, ...,  0.10574823,\n",
       "         -0.09017627, -0.10293557]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prunable_weights = [l2.get_weights()[0], l3.get_weights()[0], l4.get_weights()[0], l5.get_weights()[0], op.get_weights()[0]]\n",
    "prunable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 165us/sample - loss: 0.0927 - acc: 0.9749\n",
      "Validation loss:  0.09271794773282017\n",
      "Validation accuracy before pruning:  0.9749\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print('Validation loss: ', val_loss)\n",
    "print('Validation accuracy before pruning: ', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunPerct =[0, 25, 50, 60, 70, 80, 90, 95, 97, 99]\n",
    "acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanket\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after pruning 0% of weights: 0.9736999869346619 \n",
      "Accuracy after pruning 25% of weights: 0.9732999801635742 \n",
      "Accuracy after pruning 50% of weights: 0.9729999899864197 \n",
      "Accuracy after pruning 60% of weights: 0.9721999764442444 \n",
      "Accuracy after pruning 70% of weights: 0.9677000045776367 \n",
      "Accuracy after pruning 80% of weights: 0.9036999940872192 \n",
      "Accuracy after pruning 90% of weights: 0.7073000073432922 \n",
      "Accuracy after pruning 95% of weights: 0.5134000182151794 \n",
      "Accuracy after pruning 97% of weights: 0.3154999911785126 \n"
     ]
    }
   ],
   "source": [
    "for i in prunPerct:\n",
    "    pruned_weights = []\n",
    "    for weight in prunable_weights:\n",
    "        flattened = np.absolute(np.ndarray.flatten(weight))\n",
    "        length = len(flattened)\n",
    "        sort = np.sort(flattened)\n",
    "        threshold = sort[int((i/100) * length)]\n",
    "        for row in range(weight.shape[0]):\n",
    "            for col in range(weight.shape[1]):\n",
    "                if (abs(weight[row][col]) < threshold):\n",
    "                    weight[row][col] = 0\n",
    "    \n",
    "        pruned_weights.append(weight)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28 * 28) / 255.0\n",
    "    \n",
    "    w1 = tf.Variable(initial_value = pruned_weights[0]) \n",
    "    w2 = tf.Variable(initial_value = pruned_weights[1])\n",
    "    w3 = tf.Variable(initial_value = pruned_weights[2])\n",
    "    w4 = tf.Variable(initial_value = pruned_weights[3])\n",
    "    \n",
    "    out_w = tf.Variable(initial_value =pruned_weights[4])\n",
    "    output = tf.placeholder(tf.int32, [None])\n",
    "    inputs = tf.placeholder(tf.float32, [None, 784])\n",
    "    \n",
    "    l1 = tf.nn.relu(tf.matmul(inputs, w1))\n",
    "    l2 = tf.nn.relu(tf.matmul(l1, w2))\n",
    "    l3 = tf.nn.relu(tf.matmul(l2, w3))\n",
    "    l4 = tf.nn.relu(tf.matmul(l3, w4))\n",
    "    out = tf.nn.softmax(tf.matmul(l4, out_w))\n",
    "    predictions = tf.cast(tf.math.argmax(out, axis=1), tf.int32)\n",
    "    \n",
    "    acc, acc_percentage = tf.metrics.accuracy(labels=output, predictions=predictions)\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    accuracy = sess.run(acc_percentage, feed_dict={inputs: x_test, output: y_test})\n",
    "    print('Accuracy after pruning {}% of weights: {} '.format(i,  accuracy))\n",
    "    acc.append = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
